# project-object_detecting

얼굴인식후 화면가운데로 정렬하기 위해 서브모터(pan,tilt)움직임
손(MAX = 1)의 움직임을 인식하여 수화(ASL)로 단어출력가능

getchar.py : 키보드에서 사용자 입력을 실시간으로 확인(리눅스)
getcharr.py : 키보드에서 사용자 입력을 실시간으로 확인(윈도우)

webcam_blue2.py : 파란색인식 (파란색물건이 화면에 잡히면 물건의 센터로 부터 높이와 넒이를 구해 박스 침, 박스의 센터값과 움직여야하는 값 출력)
webcam_blue3.py : 파란색 인식후 서브모터(아두이노로 컨트롤)에 부착된 카메라가 움직여 파란물체를 화면 가운데로 정렬

pt_control.ino : 아두이노 코드(pan x : 서브모터 9번, tilt y : 서브모터 10번)

haarcascade_frontalface_alt.xml : 얼굴(눈, 코, 입)인식 xml파일
face_detect_cam.py : 내장cam으로 얼굴인식
webcam_face.py : 얼굴인식후 서브모터로 화면 가운데로 정렬
webcam_hand_number_line.py : 화면에 손(MAX = 1)이 잡히면 손가락의 개수로 숫자 출력(0 - 10) 

-----------------------------------------------------------------최종-----------------------------------------------------------------

webcam_asl_knn : 화면에 얼굴을 트래킹하면서 손의 움직임(벡터와 벡터 사이의 각도- KNN학습)과 매핑된 수화(ASL)출력

1.카메라로 얼굴을 인식(haarcascade_frontalface_alt.xml)
 -눈, 코, 입중 하나라도 없을시 얼굴로 인식 안함
 
2.인식된 얼굴(객체)의 중심좌표를 구한 후 크기와 넓이를 구해 박스를 만든다

3.중심값이 카메라 화면의 중심(320,240)이 되게한다 => cam(640*480)

3-1 얼굴이 좌측으로 치우쳐있을 때: pan값을 줄여 320이 되게 함
    -현재 pan값을 아두이노로 넘겨 320이 될 때까지 서브모터를 우측으로 돌린다
3-1 얼굴이 위로 치우쳐있을 때: tilt값을 늘여 2400이 되게 함
    -현재 tilt값을 아두이노로 넘겨 240이될 때까지 서브모터를 우측으로 돌린다
    
4.손이 인식될 경우 손의 관절의 각도, 움직임으로 현재 제스쳐인식(KNN학습)

5.인식된 제스쳐에 매핑된 수화(ASL)을 화면 하단에 표시
  -3초 이상 같은 제스쳐를 취한다면 사용자가 원하는 수화로 인식함


